{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T09:51:35.700536Z",
     "start_time": "2023-04-26T09:51:28.532510Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "#data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import kruskal, pearsonr, ttest_ind\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "# Metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import log_loss, classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# ML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "from logic.feature_extraction import FeatureExtraction\n",
    "from logic.text_analysis import TextAnalysis\n",
    "from root import DIR_INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T09:51:35.767285Z",
     "start_time": "2023-04-26T09:51:35.691326Z"
    }
   },
   "outputs": [],
   "source": [
    "lang = 'es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T22:13:29.642085Z",
     "start_time": "2023-04-25T22:13:29.603815Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ftrain = '{0}{1}{2}{3}'.format(DIR_INPUT, 'Valence_train_oc_', lang, '.csv')\n",
    "ftest = '{0}{1}{2}{3}'.format(DIR_INPUT, 'Valence_test_oc_', lang, '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T22:13:40.430982Z",
     "start_time": "2023-04-25T22:13:29.635937Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ta = TextAnalysis(lang=lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T22:13:44.854254Z",
     "start_time": "2023-04-25T22:13:40.438981Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features = FeatureExtraction(lang=lang, text_analysis=ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(ftrain, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data['clean_text'] = train_data['Tweet'].apply(lambda x: ta.clean_text(x))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.drop(['ID', 'Tweet', 'Dimension', 'Description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Intensity'] = train['Intensity'].replace([-2, -3], -1)\n",
    "train['Intensity'] = train['Intensity'].replace([2, 3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(ftest, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_data['clean_text'] = test_data['Tweet'].apply(lambda x: ta.clean_text(x))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_data.drop(['ID', 'Tweet', 'Dimension', 'Description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Intensity'] = test['Intensity'].replace([-2, -3], -1)\n",
    "test['Intensity'] = test['Intensity'].replace([2, 3], 1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train = train['clean_text']\n",
    "y_train = train['Intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_test = test['clean_text']\n",
    "y_test = test['Intensity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train = features.get_feature_phonestheme(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train = preprocessing.normalize(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_test = features.get_feature_phonestheme(x_test)\n",
    "x_test = preprocessing.normalize(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('**Sample train:', sorted(Counter(y_train).items()))\n",
    "print('**Sample test:', sorted(Counter(y_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ros_train = RandomUnderSampler(random_state=1000)\n",
    "x_train, y_train = ros_train.fit_resample(x_train, y_train)\n",
    "print('**OverSampler train:', sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ros_test = RandomOverSampler(random_state=1000)\n",
    "x_test, y_test = ros_test.fit_resample(x_test, y_test)\n",
    "print('**RandomOverSampler test:', sorted(Counter(y_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "k_fold = ShuffleSplit(n_splits=10, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "models = [(\"RF\", RandomForestClassifier(max_depth=200, n_estimators=200, random_state=42)),\n",
    "          (\"DT\", DecisionTreeClassifier(max_depth = 4)),\n",
    "          (\"NB\", GaussianNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalResults = []\n",
    "cmList = []\n",
    "for name, model in models:\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    for train_index, test_index in k_fold.split(x_train, y_train):\n",
    "        data_train = x_train[train_index]\n",
    "        target_train = y_train[train_index]\n",
    "\n",
    "        data_test = x_train[test_index]\n",
    "        target_test = y_train[test_index]\n",
    "        \n",
    "        model.fit(data_train, target_train)\n",
    "        predict = model.predict(data_test)\n",
    "         # Accuracy\n",
    "        accuracy = accuracy_score(target_test, predict, normalize=True)\n",
    "        accuracies.append(accuracy)\n",
    "        # Precision\n",
    "        precision = precision_score(target_test, predict, average=\"macro\")\n",
    "        precisions.append(precision)\n",
    "        # recall\n",
    "        recall = recall_score(target_test, predict, average=\"macro\")\n",
    "        recalls.append(recall)\n",
    "        # f1\n",
    "        f1 = f1_score(target_test, predict, average=\"macro\")\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    y_predict = model.predict(x_test)\n",
    "    cm= confusion_matrix(y_test, y_predict)\n",
    "    cmList.append((name,cm))\n",
    "    \n",
    "    finalResults.append({'name':name, \n",
    "                         'model': model,\n",
    "                         'accuracy': round(np.mean(accuracies), 2), \n",
    "                         'precision': round(np.mean(precisions), 2),\n",
    "                         'recall': round(np.mean(recalls), 2),\n",
    "                         'f1': round(np.mean(f1s), 2),\n",
    "                         'confusion_matrix': cm\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame.from_dict(finalResults)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for name , i in cmList:\n",
    "    plt.figure()\n",
    "    sns.heatmap(i , annot =True, linewidth=0.8,fmt=\".1f\")\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
